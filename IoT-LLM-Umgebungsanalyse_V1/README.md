# IoT LLM Umgebungsanalyse

Ein IoT-System zur visuellen Objekterkennung in Echtzeit mit einem ESP32-CAM Modul, einem MQTT-Trigger und einem Flask-Webserver. Erkennt Objekte auf aufgenommenen Bildern, wandelt die Ergebnisse in Sprache um und streamt Audio zurÃ¼ck an ein ESP32-GerÃ¤t.

## Projektidee

Das Projekt kombiniert Edge-GerÃ¤te, Cloud-Services und KI-basierte Bildanalyse. Ein ESP32 sendet einen Trigger Ã¼ber MQTT, ein Python-Server macht ein Foto, analysiert es mit einem Bild-KI-Modell, konvertiert das Ergebnis zu Sprache und spielt die Audiodatei Ã¼ber das ESP-Modul ab.

---

## ğŸ—‚ï¸ Projektstruktur

```text
projekt/
â”œâ”€â”€ main_L.py             
â”œâ”€â”€ mqtt.py               
â”œâ”€â”€ Kamera.py              
â”œâ”€â”€ gTTS.py                
â”œâ”€â”€ output.mp3             
â”œâ”€â”€ output.wav            
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ prompt.txt       
â”‚   â””â”€â”€ screenshots/
â”‚       â””â”€â”€ screenshot.jpg 
```

---

## Setup & AusfÃ¼hrung

### Voraussetzungen

- Python 3.8+
- AbhÃ¤ngigkeiten:
  ```bash
  pip install flask paho-mqtt opencv-python requests gtts pydub
  ```

- Ollama installiert (fÃ¼r Bildanalyse mit lokalem Modell)

### Projekt starten

1. **Flask-Server starten** (inkl. Kamera-Stream & API):
   ```bash
   python3 main_L.py
   ```

2. **ESP32-CAM konfigurieren**, um den Livestream unter z.â€¯B. `http://192.168.179.215:81/stream` verfÃ¼gbar zu machen.

3. **ESP32-MQTT-Button** sendet Trigger an:
   ```
   Topic: kamera/trigger
   Broker: 192.168.179.244:1883
   ```

---

## Webinterface

- **Startseite**: `http://<Deine-IP>:5000`
- Funktionen:
  - Live-Stream der Kamera
  - Letzter Screenshot
  - Button zur manuellen Bildaufnahme
  - Automatische Aktualisierung des Analyse-Prompts
  - Sprachausgabe bei Klick oder Trigger

---

## Analyse & Verarbeitung

### Kamera.py

Verwendet das lokale `ollama`-Modell (z.â€¯B. gemma3:4b), um das Bild in eine Liste von Objekten (Nomen) umzuwandeln und in `prompt.txt` zu speichern.

### gTTS.py

Liest `prompt.txt`, generiert mit gTTS eine MP3-Datei und konvertiert diese in WAV.

### Flask-Endpunkte

- `/button_pressed` â€“ Macht Screenshot & startet Analyse  
- `/get_prompt [GET]` â€“ Gibt aktuellen Prompt zurÃ¼ck  
- `/get_prompt [POST]` â€“ Startet Text-to-Speech & schickt WAV an ESP  
- `/video_feed` â€“ Streamt Kamera-Livestream als MJPEG  

---

## Features

- MQTT-basierter Trigger (ESP32-kompatibel)  
- Live-Videostream via OpenCV  
- Screenshot per Button oder Trigger  
- Bildanalyse mit Ollama (lokales LLM)  
- Ausgabe als Sprache (gTTS â†’ WAV)  
- Audio-Upload an ESP32 zur Wiedergabe  

---

## Beispielablauf

1. ESP32 sendet Trigger via MQTT  
2. Server speichert Screenshot vom Stream  
3. Kamera.py analysiert Bild (â†’ prompt.txt)  
4. gTTS erzeugt Sprachausgabe (output.wav)  
5. WAV-Datei wird an das ESP32-Modul gesendet  

---

## Hinweise

- Stelle sicher, dass das Ollama-Modell lokal verfÃ¼gbar ist (`ollama run gemma3:4b`)  
- Passe IP-Adressen in `main_L.py`, `mqtt.py` und HTML ggf. an dein Netzwerk an  
- Achte auf Berechtigungen zum Schreiben in `static/` und `templates/`  

---
